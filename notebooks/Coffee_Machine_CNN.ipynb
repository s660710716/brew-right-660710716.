{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNUs3U8JZx74"
      },
      "outputs": [],
      "source": [
        "pip install resampy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "-bFzOY1NZz_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "PlQib7viaTya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/DST86/machine-sound-daata'\n",
        "print(os.listdir(data_path))"
      ],
      "metadata": {
        "id": "QqHuYf3xabY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filelist = os.listdir(data_path)\n",
        "\n",
        "for filename in filelist:\n",
        "  print(filename)"
      ],
      "metadata": {
        "id": "iDtSpCWCalMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "b4u6CSagam1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump\n",
        "from pickle import load"
      ],
      "metadata": {
        "id": "o8wg-_K_a0EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_path+\"/train\"\n",
        "os.listdir(train_data)"
      ],
      "metadata": {
        "id": "EJ0KMxYia241"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = data_path+\"/val\"\n",
        "os.listdir(val_data)"
      ],
      "metadata": {
        "id": "jGHPJ4vTcP1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data_path+\"/test\"\n",
        "os.listdir(test_data)"
      ],
      "metadata": {
        "id": "q5Ovu3lUcTzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_train = train_data+\"/n_*.wav\"\n",
        "abnormal_train = train_data+\"/a_*.wav\""
      ],
      "metadata": {
        "id": "9BYGjxoocYxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_train"
      ],
      "metadata": {
        "id": "8QMVy63mcr8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_val = val_data+\"/n_*.wav\"\n",
        "abnormal_val = val_data+\"/a_*.wav\""
      ],
      "metadata": {
        "id": "WKLV-NeldETu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display"
      ],
      "metadata": {
        "id": "euUr6z2HcwNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "normal_train_signals = [\n",
        "    librosa.load(p)[0] for p in glob.glob(normal_train)\n",
        "]\n",
        "\n",
        "abnormal_train_signals = [\n",
        "    librosa.load(p)[0] for p in glob.glob(abnormal_train)\n",
        "]\n",
        "\n",
        "normal_val_signals = [\n",
        "    librosa.load(p)[0] for p in glob.glob(normal_val)\n",
        "]\n",
        "\n",
        "abnormal_val_signals = [\n",
        "    librosa.load(p)[0] for p in glob.glob(abnormal_val)\n",
        "]"
      ],
      "metadata": {
        "id": "YqcCHZPucyby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b630cc4c"
      },
      "source": [
        "print(\"Shape of normal_train_signals:\", np.array(normal_train_signals, dtype=object).shape)\n",
        "print(\"Shape of abnormal_train_signals:\", np.array(abnormal_train_signals, dtype=object).shape)\n",
        "print(\"Shape of normal_val_signals:\", np.array(normal_val_signals, dtype=object).shape)\n",
        "print(\"Shape of abnormal_val_signals:\", np.array(abnormal_val_signals, dtype=object).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset(dataset, filename):\n",
        "    dump(dataset, open(filename, 'wb'))\n",
        "    print('Saved: %s' % filename)"
      ],
      "metadata": {
        "id": "SKvSXTvTfKAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetFile = 'coffee_train.pkl'\n",
        "save_dataset([normal_train_signals, abnormal_train_signals], datasetFile)"
      ],
      "metadata": {
        "id": "1va0S0_8fNmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetFile_val = 'coffee_val.pkl'\n",
        "save_dataset([normal_val_signals, abnormal_val_signals], datasetFile_val)"
      ],
      "metadata": {
        "id": "b4b3iU0vfdUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "    return load(open(filename, 'rb'))\n",
        "\n",
        "[normal_train_signals, abnormal_train_signals] = load_dataset(datasetFile)"
      ],
      "metadata": {
        "id": "KuJzgjLif0vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(normal_train_signals), len(abnormal_train_signals)"
      ],
      "metadata": {
        "id": "vCgNPR7YgEPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[normal_val_signals, abnormal_val_signals] = load_dataset(datasetFile_val)"
      ],
      "metadata": {
        "id": "u0tBf5FFgLaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(normal_val_signals), len(abnormal_val_signals)"
      ],
      "metadata": {
        "id": "J00fN03igSNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "for i, x in enumerate(normal_train_signals[:10]):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    librosa.display.waveshow(x[:10000])\n",
        "    plt.ylim(-1, 1)"
      ],
      "metadata": {
        "id": "O_F7CtPlgY1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "for i, x in enumerate(abnormal_train_signals[:10]):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    librosa.display.waveshow(x[:10000])\n",
        "    plt.ylim(-1, 1)"
      ],
      "metadata": {
        "id": "ZaC067brgeEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(signal):\n",
        "    return [\n",
        "        librosa.feature.zero_crossing_rate(signal)[0, 0],\n",
        "        librosa.feature.spectral_centroid(y=signal)[0, 0],\n",
        "    ]"
      ],
      "metadata": {
        "id": "n_hF4QIvgmtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_train_features = np.array([extract_features(x) for x in normal_train_signals])\n",
        "abnormal_train_features = np.array([extract_features(x) for x in abnormal_train_signals])"
      ],
      "metadata": {
        "id": "Aan5y_vOgrl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_val_features = np.array([extract_features(x) for x in normal_val_signals])\n",
        "abnormal_val_features = np.array([extract_features(x) for x in abnormal_val_signals])"
      ],
      "metadata": {
        "id": "dZETufLWg2Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normal_train_features.shape)\n",
        "print(abnormal_train_features.shape)\n",
        "print(normal_val_features.shape)\n",
        "print(abnormal_val_features.shape)"
      ],
      "metadata": {
        "id": "Owshkgd9g7wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normal_train_features[10])\n",
        "print(abnormal_train_features[10])\n",
        "print(normal_val_features[10])\n",
        "print(abnormal_val_features[10])"
      ],
      "metadata": {
        "id": "vvwHkrNOhGOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "plt.hist(normal_train_features[:,0], color='b', range=(0, 0.2), alpha=0.5, bins=20)\n",
        "plt.hist(abnormal_train_features[:,0], color='r', range=(0, 0.2), alpha=0.5, bins=20)\n",
        "plt.legend(('normal', 'abnormal'))\n",
        "plt.xlabel('Zero Crossing Rate')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "HdjmHgq1hcmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "plt.hist(normal_train_features[:,1], color='b', range=(0, 4000), bins=30, alpha=0.6)\n",
        "plt.hist(abnormal_train_features[:,1], color='r', range=(0, 4000), bins=30, alpha=0.6)\n",
        "plt.legend(('normal', 'abnormal'))\n",
        "plt.xlabel('Spectral Centroid (frequency bin)')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "4I6uVJJWhlew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train_table = np.vstack((normal_train_features, abnormal_train_features))\n",
        "print(feature_train_table.shape)"
      ],
      "metadata": {
        "id": "TdBpFtFvhvWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_val_table = np.vstack((normal_val_features, abnormal_val_features))\n",
        "print(feature_val_table.shape)"
      ],
      "metadata": {
        "id": "n8D9Bkh1h0yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
        "training_features = scaler.fit_transform(feature_train_table)\n",
        "print(training_features.min(axis=0))\n",
        "print(training_features.max(axis=0))"
      ],
      "metadata": {
        "id": "1TgZJ2LBh9C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
        "val_features = scaler.fit_transform(feature_val_table)\n",
        "print(val_features.min(axis=0))\n",
        "print(val_features.max(axis=0))"
      ],
      "metadata": {
        "id": "myjP-7wDiGzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(training_features[:489,0], training_features[:489,1], c='b')\n",
        "plt.scatter(training_features[489:,0], training_features[489:,1], c='r')\n",
        "plt.xlabel('Zero Crossing Rate')\n",
        "plt.ylabel('Spectral Centroid')"
      ],
      "metadata": {
        "id": "KLDl-1Z6iS_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_total = [0 for i in range(489)] + [1 for i in range(175)]\n",
        "y_val_total = [0 for i in range(119)] + [1 for i in range(47)]"
      ],
      "metadata": {
        "id": "fxmpjcEMiWPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded = to_categorical(y_train_total)\n",
        "y_val_encoded = to_categorical(y_val_total)"
      ],
      "metadata": {
        "id": "unFvqXc5jCKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded[:10]"
      ],
      "metadata": {
        "id": "wp9sYSisjGPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = training_features\n",
        "y_train = y_train_encoded\n",
        "x_val = val_features\n",
        "y_val = y_val_encoded"
      ],
      "metadata": {
        "id": "wc3ZvYLtjIjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "pQ-mlA_Gjmj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val.shape, y_val.shape"
      ],
      "metadata": {
        "id": "B-MevtRtjoPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input"
      ],
      "metadata": {
        "id": "OeQh6IWHkEW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(2,)))\n",
        "    model.add(Dense(8))\n",
        "    model.add(LeakyReLU(negative_slope=0.1))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "Zud_a8wbkREe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()\n",
        "adam_optim = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam_optim, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FZ6ARQ0ckTPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=1,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data = (x_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "oQfkd4KPkpT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go"
      ],
      "metadata": {
        "id": "Vaew7TOZkt2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title='', range=[0, 1]))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "CcwDEKHkl9bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title='',range=[0, 1]))\n",
        "fig2 = go.Figure(data = data, layout=layout1)\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "OP9Tw6T0l-M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Model**"
      ],
      "metadata": {
        "id": "bJSVfkyAmQoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ixDl_zVJmCXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/drive/MyDrive/DST86/machine-sound-daata/train/a_00000004_5000.wav'\n",
        "audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "\n",
        "print(audio.shape, sample_rate)\n",
        "\n",
        "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "print(mfccs.shape)"
      ],
      "metadata": {
        "id": "NgPCLRR5mH4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.display.specshow(mfccs, sr=sample_rate, x_axis='time')"
      ],
      "metadata": {
        "id": "jWmRfq9_nMVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pad_len = 100\n",
        "\n",
        "def extract_features(file_name):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "2vOuTG7inPKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71925494"
      },
      "source": [
        "normal_train_features = []\n",
        "for file_name in glob.glob(normal_train):\n",
        "    data = extract_features(file_name)\n",
        "    normal_train_features.append(data)\n",
        "\n",
        "abnormal_train_features = []\n",
        "for file_name in glob.glob(abnormal_train):\n",
        "    data = extract_features(file_name)\n",
        "    abnormal_train_features.append(data)\n",
        "\n",
        "normal_val_features = []\n",
        "for file_name in glob.glob(normal_val):\n",
        "    data = extract_features(file_name)\n",
        "    normal_val_features.append(data)\n",
        "\n",
        "abnormal_val_features = []\n",
        "for file_name in glob.glob(abnormal_val):\n",
        "    data = extract_features(file_name)\n",
        "    abnormal_val_features.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_train_features[0].shape"
      ],
      "metadata": {
        "id": "nU6vKl7wnesJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train_table = np.vstack((normal_train_features, abnormal_train_features))\n",
        "print(feature_train_table.shape)"
      ],
      "metadata": {
        "id": "jHbvwZFMpsSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train_table = feature_train_table.reshape(feature_train_table.shape[0], feature_train_table.shape[1], feature_train_table.shape[2], 1)\n",
        "print(feature_train_table.shape)"
      ],
      "metadata": {
        "id": "H6dvKtGYp1IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded[:10]"
      ],
      "metadata": {
        "id": "AVZwg43cpW-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_val_table = np.vstack((normal_val_features, abnormal_val_features))"
      ],
      "metadata": {
        "id": "5C23ViktphNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_val_table = feature_val_table.reshape(feature_val_table.shape[0], feature_val_table.shape[1], feature_val_table.shape[2], 1)\n",
        "print(feature_val_table.shape)"
      ],
      "metadata": {
        "id": "plFhov9VqIrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = feature_train_table\n",
        "x_val = feature_val_table\n",
        "y_train = y_train_encoded\n",
        "y_val = y_val_encoded"
      ],
      "metadata": {
        "id": "PPaUyNswqamY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "T75ZepYSqNu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 40\n",
        "num_columns = 216\n",
        "num_channels = 1\n",
        "num_batch_size = 64\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "m7drRFk-qTj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(num_rows, num_columns, num_channels)))\n",
        "model.add(Conv2D(filters=16, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "ZISJJq5cqtrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "id": "IknZeGp3qwA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "metadata": {
        "id": "Hx-bZhG3ucn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=epochs, validation_data=(x_val, y_val), verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "TmoC5BQcqyAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "cIhOYOmDq0AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig2 = go.Figure(data = data, layout=layout1)\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "SJEtePQOrFhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model(\"/content/best_model.keras\")"
      ],
      "metadata": {
        "id": "W2q5U3sVyAOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_res = model.evaluate(x_train, y_train, verbose=0, return_dict=True)\n",
        "val_res   = model.evaluate(x_val,   y_val,   verbose=0, return_dict=True)\n",
        "\n",
        "acc_key = next(k for k in train_res.keys() if k in\n",
        "               ('accuracy', 'binary_accuracy', 'categorical_accuracy',\n",
        "                'sparse_categorical_accuracy'))\n",
        "\n",
        "print(f\"Training  - loss: {train_res['loss']:.4f}, acc: {train_res[acc_key]:.4f}\")\n",
        "print(f\"Validation- loss: {val_res['loss']:.4f}, acc: {val_res[acc_key]:.4f}\")\n"
      ],
      "metadata": {
        "id": "LhkAnD031Rxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(x_val)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_val, axis=1)"
      ],
      "metadata": {
        "id": "VE2QzDvstJ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "lT6Y4Q4vtNOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['normal', 'abnormal'],digits=4)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "RL7DBBwvr6yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "056a68b7"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['normal', 'abnormal'], yticklabels=['normal', 'abnormal'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGvz3Uhutba2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}